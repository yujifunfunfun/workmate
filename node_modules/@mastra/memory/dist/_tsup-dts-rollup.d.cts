import type { AiMessageType } from '@mastra/core';
import type { CoreMessage } from '@mastra/core';
import type { CoreTool } from '@mastra/core';
import { MastraMemory } from '@mastra/core/memory';
import type { MemoryConfig } from '@mastra/core/memory';
import { MemoryProcessor } from '@mastra/core/memory';
import { MemoryProcessor as MemoryProcessor_2 } from '@mastra/core';
import type { MemoryProcessorOpts } from '@mastra/core';
import type { MessageType } from '@mastra/core/memory';
import type { SharedMemoryConfig } from '@mastra/core/memory';
import type { StorageGetMessagesArg } from '@mastra/core/storage';
import type { StorageThreadType } from '@mastra/core/memory';
import type { TiktokenBPE } from 'js-tiktoken/lite';

/**
 * Concrete implementation of MastraMemory that adds support for thread configuration
 * and message injection.
 */
export declare class Memory extends MastraMemory {
    constructor(config?: SharedMemoryConfig);
    private validateThreadIsOwnedByResource;
    query({ threadId, resourceId, selectBy, threadConfig, }: StorageGetMessagesArg & {
        threadConfig?: MemoryConfig;
    }): Promise<{
        messages: CoreMessage[];
        uiMessages: AiMessageType[];
    }>;
    rememberMessages({ threadId, resourceId, vectorMessageSearch, config, }: {
        threadId: string;
        resourceId?: string;
        vectorMessageSearch?: string;
        config?: MemoryConfig;
    }): Promise<{
        threadId: string;
        messages: CoreMessage[];
        uiMessages: AiMessageType[];
    }>;
    getThreadById({ threadId }: {
        threadId: string;
    }): Promise<StorageThreadType | null>;
    getThreadsByResourceId({ resourceId }: {
        resourceId: string;
    }): Promise<StorageThreadType[]>;
    saveThread({ thread, memoryConfig, }: {
        thread: StorageThreadType;
        memoryConfig?: MemoryConfig;
    }): Promise<StorageThreadType>;
    updateThread({ id, title, metadata, }: {
        id: string;
        title: string;
        metadata: Record<string, unknown>;
    }): Promise<StorageThreadType>;
    deleteThread(threadId: string): Promise<void>;
    private chunkText;
    private hasher;
    private embeddingCache;
    private firstEmbed;
    private embedMessageContent;
    saveMessages({ messages, memoryConfig, }: {
        messages: MessageType[];
        memoryConfig?: MemoryConfig;
    }): Promise<MessageType[]>;
    protected updateMessagesToHideWorkingMemory(messages: MessageType[]): MessageType[];
    protected parseWorkingMemory(text: string): string | null;
    getWorkingMemory({ threadId }: {
        threadId: string;
    }): Promise<string | null>;
    private saveWorkingMemory;
    getSystemMessage({ threadId, memoryConfig, }: {
        threadId: string;
        memoryConfig?: MemoryConfig;
    }): Promise<string | null>;
    defaultWorkingMemoryTemplate: string;
    private getWorkingMemoryWithInstruction;
    private getWorkingMemoryToolInstruction;
    getTools(config?: MemoryConfig): Record<string, CoreTool>;
}

/**
 * Self-heals message ordering to ensure tool calls are directly before their matching tool results.
 * This is needed due to a bug where messages were saved in the wrong order. That bug is fixed, but this code ensures any tool calls saved in the wrong order in the past will still be usable now.
 */
export declare function reorderToolCallsAndResults(messages: MessageType[]): MessageType[];

/**
 * Limits the total number of tokens in the messages.
 * Uses js-tiktoken with o200k_base encoding by default for accurate token counting with modern models.
 */
declare class TokenLimiter extends MemoryProcessor {
    private encoder;
    private maxTokens;
    TOKENS_PER_MESSAGE: number;
    TOKENS_PER_TOOL: number;
    TOKENS_PER_CONVERSATION: number;
    /**
     * Create a token limiter for messages.
     * @param options Either a number (token limit) or a configuration object
     */
    constructor(options: number | TokenLimiterOptions);
    process(messages: CoreMessage[], { systemMessage, memorySystemMessage, newMessages }?: MemoryProcessorOpts): CoreMessage[];
    countTokens(message: string | CoreMessage): number;
}
export { TokenLimiter }
export { TokenLimiter as TokenLimiter_alias_1 }

/**
 * Configuration options for TokenLimiter
 */
declare interface TokenLimiterOptions {
    /** Maximum number of tokens to allow */
    limit: number;
    /** Optional encoding to use (defaults to o200k_base which is used by gpt-4o) */
    encoding?: TiktokenBPE;
}

/**
 * Filters out tool calls and results from messages.
 * By default (with no arguments), excludes all tool calls and their results.
 * Can be configured to exclude only specific tools by name.
 */
declare class ToolCallFilter extends MemoryProcessor_2 {
    private exclude;
    /**
     * Create a filter for tool calls and results.
     * @param options Configuration options
     * @param options.exclude List of specific tool names to exclude. If not provided, all tool calls are excluded.
     */
    constructor(options?: {
        exclude?: string[];
    });
    process(messages: CoreMessage[]): CoreMessage[];
}
export { ToolCallFilter }
export { ToolCallFilter as ToolCallFilter_alias_1 }

export declare const updateWorkingMemoryTool: CoreTool;

export { }
